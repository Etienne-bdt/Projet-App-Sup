{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Apprentissage Supervisée: Change detection in bi-temporal remote sensing image "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clément Guigon - Ophélia Urbing - Etienne Bardet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TVF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from network import *\n",
    "from network import *\n",
    "from tqdm import tqdm\n",
    "from utils import *\n",
    "from skimage import exposure\n",
    "from torcheval.metrics.functional import binary_f1_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Dataset class for our change detection dataset\n",
    "\n",
    "class ChangeDetectionDataset(Dataset):\n",
    "    def __init__(self, csv_file=\"data.csv\", data_dir=\"./data\", batch_size=1, transform=None, crop_size=128):\n",
    "        #repeat the data 5 times to have more data\n",
    "        self.data = pd.read_csv(csv_file).sample(frac=30, replace=True)\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "        self.crop_size = crop_size\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def random_crop(self, img1, img2, cm, size):\n",
    "        x = np.random.randint(0, img1.shape[2]-size)\n",
    "        y = np.random.randint(0, img1.shape[1]-size)\n",
    "        img1 = img1[:,y:y+size, x:x+size]\n",
    "        img2 = img2[:,y:y+size, x:x+size]\n",
    "        cm = cm[0:1, y:y+size, x:x+size]\n",
    "        return img1, img2, cm\n",
    "\n",
    "    def random_flip(self, img1,img2,cm, chance=0.5):\n",
    "        if (np.random.randint(0,1)> chance):\n",
    "            img1 = TVF.hflip(img1)\n",
    "            img2 = TVF.hflip(img2)\n",
    "            cm = TVF.hflip(cm)\n",
    "\n",
    "        if (np.random.randint(0,1)> chance):\n",
    "            img1 = TVF.vflip(img1)\n",
    "            img2 = TVF.vflip(img2)\n",
    "            cm = TVF.vflip(cm)\n",
    "\n",
    "        return img1, img2, cm\n",
    "\n",
    "    def apply_hist_dynamic(self, source, target):\n",
    "        for i in range(3):\n",
    "            mean1_cn = torch.mean(source[i,:,:])\n",
    "            std1_cn = torch.std(source[i,:,:])\n",
    "            mean2_cn = torch.mean(target[i,:,:])\n",
    "            std2_cn = torch.std(target[i,:,:])\n",
    "            target[i,:,:] = ((target[i,:,:] - mean2_cn) / std2_cn)*std1_cn + mean1_cn\n",
    "        return target\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1 = read_image(self.data_dir+'/'+self.data.iloc[idx,0])\n",
    "        img2 = read_image(self.data_dir+'/'+self.data.iloc[idx,1])\n",
    "        cm = read_image(self.data_dir+'/'+self.data.iloc[idx,2])\n",
    "\n",
    "        img1Tensor = torch.zeros((3, self.crop_size, self.crop_size), dtype=torch.float32)\n",
    "        img2Tensor = torch.zeros((3, self.crop_size, self.crop_size), dtype=torch.float32)\n",
    "        cmTensor = torch.zeros((1, self.crop_size, self.crop_size), dtype=torch.float32)\n",
    "        \n",
    "        crop1, crop2, cropcm = self.random_crop(img1[:,:,:], img2[:,:,:], cm[:,:,:], self.crop_size)\n",
    "        crop1, crop2, cropcm = self.random_flip(crop1[:,:,:], crop2[:,:,:], cropcm[:,:,:])\n",
    "        img1Tensor[:,:,:] = crop1.float()/255\n",
    "        img2Tensor[:,:,:] = crop2.float()/255\n",
    "        cmTensor[:,:,:] = cropcm.float()/255\n",
    "        #apply the same transformation to all images as batch dimension\n",
    "        img2Tensor = self.apply_hist_dynamic(img1Tensor, img2Tensor)\n",
    "        img2Tensor = torch.clamp(img2Tensor, 0, 1)\n",
    "        img1Tensor, img2Tensor = torch.Tensor(exposure.equalize_adapthist(img1Tensor.permute(1,2,0).numpy())).permute(2,0,1), torch.Tensor(exposure.equalize_adapthist(img2Tensor.permute(1,2,0).numpy())).permute(2,0,1)\n",
    "        return img1Tensor, img2Tensor, cmTensor\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataLoader class for our change detection dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple DataLoader class for our change detection dataset\n",
    "batch_size = 32\n",
    "\n",
    "weights = class_weights(\"data.csv\")\n",
    "weights = torch.tensor(weights[0]/weights[1]).to(device)\n",
    "\n",
    "train_dataset= ChangeDetectionDataset(data_dir=\"data\",csv_file=\"train.csv\", batch_size=batch_size, transform=None)\n",
    "val_dataset = ChangeDetectionDataset(data_dir=\"data\",csv_file=\"val.csv\", batch_size=1, transform=None)\n",
    "train_loader = DataLoader(batch_size=batch_size, dataset=train_dataset, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to display a batch of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple function to display a batch of images\n",
    "\n",
    "def show_batch(batch):\n",
    "    img1s, img2s, cms = batch\n",
    "\n",
    "    for i in range(len(img1s)):\n",
    "        img1 = img1s[i,:,:,:]\n",
    "        img2 = img2s[i,:,:,:]\n",
    "        cm = cms[i,:,:,:]\n",
    "        fig, ax = plt.subplots(1,3)\n",
    "        ax[0].imshow(img1.permute(1,2,0))\n",
    "        ax[1].imshow(img2.permute(1,2,0))\n",
    "        ax[2].imshow(cm.permute(1,2,0), cmap='gray')\n",
    "        plt.show()\n",
    "#a = next(iter(train_loader))\n",
    "#show_batch(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 30\n",
    "learning_rate = 0.0005\n",
    "model = ChangeDetectUnet(in_chan=9).to(device)\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_loss, val_loss = [], []\n",
    "train_precision, val_precision = [], []\n",
    "model = model.to(device)\n",
    "best_loss =1000\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()\n",
    "    loss_cumu, f1 = 0,0\n",
    "\n",
    "    for img1, img2, cm in tqdm(train_loader, ascii=\" >=\"):\n",
    "        img1, img2, cm = img1.to(device), img2.to(device), cm.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(img1, img2)\n",
    "        pred_binary = torch.ceil(torch.threshold(y_pred, 0.1, 0))\n",
    "        loss = loss_fn(y_pred, cm)  # Supervision profonde\n",
    "        loss_cumu += loss.item()\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Précision\n",
    "        ground_truth_flat = cm.flatten()\n",
    "        predictions_flat = pred_binary.flatten() \n",
    "\n",
    "        f1 += binary_f1_score(ground_truth_flat, predictions_flat)  \n",
    "    train_loss.append(loss_cumu / len(train_loader))\n",
    "    train_precision.append(f1/len(train_loader))\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    loss_cumu, f1 = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for img1, img2, cm in val_loader:\n",
    "            img1, img2, cm = img1.to(device), img2.to(device), cm.to(device)\n",
    "                        \n",
    "            y_pred = model(img1, img2)\n",
    "            pred_binary = torch.ceil(torch.threshold(y_pred, 0.1, 0))\n",
    "            loss = loss_fn(y_pred, cm)\n",
    "            loss_cumu += loss.item()\n",
    "  \n",
    "            ground_truth_flat = cm.flatten()\n",
    "            predictions_flat = pred_binary.flatten()\n",
    "            f1 += binary_f1_score(ground_truth_flat, predictions_flat)  \n",
    "            if loss_cumu / len(val_loader) < best_loss:\n",
    "                best_loss = loss_cumu / len(val_loader)\n",
    "                torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        val_loss.append(loss_cumu / len(val_loader))\n",
    "        val_precision.append(f1/len(val_loader))\n",
    "    \n",
    "    print(f\"Epoch {epoch+1} : Training, loss: {train_loss[-1]:.4f}, precision: {train_precision[-1]:.4f} | Validation, loss: {val_loss[-1]:.4f}, precision: {val_precision[-1]:.7f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Affichage des courbes\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Courbes de perte\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Train Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    " \n",
    "# Courbes de précision\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_precision, label='Train Precision')\n",
    "plt.plot(val_precision, label='Validation Precision')\n",
    "plt.title('Precision Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "model.eval()\n",
    "\n",
    "im1,im2,cm = next(iter(val_loader))\n",
    "\n",
    "cm_pred = model(im1,im2)#, with_attn=False)\n",
    "cm_pred_bin = torch.ceil(torch.threshold(cm_pred.detach(), 0.1, 0))\n",
    "\n",
    "### Affichage des masques\n",
    "plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(cm[0].permute(1,2,0), cmap='gray')\n",
    "plt.title(\"Ground truth\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(cm_pred.detach()[0].permute(1,2,0), cmap='plasma')\n",
    "plt.title(\"Heatmap prediction\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(cm_pred_bin.detach()[0].permute(1,2,0), cmap='gray')\n",
    "plt.title(\"Prediction\")\n",
    "plt.show()\n",
    "\n",
    "### Affichage des images bi-temporelles\n",
    "dif = im1[0]-im2[0]\n",
    "dif_norm = torch.clamp((torch.abs(dif)-torch.mean(dif)),0,1)\n",
    "plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(im1[0].permute(1,2,0))\n",
    "plt.title(\"Image 1\")\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(im2[0].permute(1,2,0))\n",
    "plt.title(\"Image 2\")\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(dif_norm.permute(1,2,0))\n",
    "plt.title(\"Normalized difference\")\n",
    "plt.figure()\n",
    "plt.imshow(dif_norm.permute(1,2,0))\n",
    "plt.imshow(cm_pred.detach()[0].permute(1,2,0), cmap='plasma', alpha=0.15)\n",
    "plt.imshow(cm[0].permute(1,2,0), cmap='winter', alpha=0.15)\n",
    "plt.title(\"Normalized difference with heatmap\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "U-Net peut être utile\n",
    "\n",
    "# Soutenance\n",
    " - Explication du problème et comment le transcrire\n",
    " - Pré-traitement des données\n",
    " - Architecture du réseau\n",
    " - Présentation des résultats\n",
    " \n",
    "# Rendu \n",
    " - Slides de présentation (10 minutes+ 10 min de questions)\n",
    " - Notebook avec le code\n",
    "\n",
    "À rendre en séance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

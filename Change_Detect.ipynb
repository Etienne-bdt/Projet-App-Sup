{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms.functional as TVF\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from network import Modele\n",
    "from tqdm import tqdm\n",
    "from utils import class_weights\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple Dataset class for our change detection dataset\n",
    "\n",
    "class ChangeDetectionDataset(Dataset):\n",
    "    def __init__(self, csv_file=\"data.csv\", data_dir=\"./data\", batch_size=1, transform=None, crop_size=128):\n",
    "        #repeat the data 5 times to have more data\n",
    "        self.data = pd.read_csv(csv_file).sample(frac=20, replace=True)\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.batch_size = batch_size\n",
    "        self.crop_size = crop_size\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def random_crop(self, img1, img2, cm, size):\n",
    "        x = np.random.randint(0, img1.shape[2]-size)\n",
    "        y = np.random.randint(0, img1.shape[1]-size)\n",
    "        img1 = img1[:,y:y+size, x:x+size]\n",
    "        img2 = img2[:,y:y+size, x:x+size]\n",
    "        cm = cm[0:1, y:y+size, x:x+size]\n",
    "        return img1, img2, cm\n",
    "\n",
    "    def random_flip(self, img1,img2,cm, chance=0.5):\n",
    "        if (np.random.randint(0,1)> chance):\n",
    "            img1 = TVF.hflip(img1)\n",
    "            img2 = TVF.hflip(img2)\n",
    "            cm = TVF.hflip(cm)\n",
    "\n",
    "        if (np.random.randint(0,1)> chance):\n",
    "            img1 = TVF.vflip(img1)\n",
    "            img2 = TVF.vflip(img2)\n",
    "            cm = TVF.vflip(cm)\n",
    "\n",
    "        return img1, img2, cm\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img1 = read_image(self.data_dir+'/'+self.data.iloc[idx,0])\n",
    "        img2 = read_image(self.data_dir+'/'+self.data.iloc[idx,1])\n",
    "        cm = read_image(self.data_dir+'/'+self.data.iloc[idx,2])\n",
    "\n",
    "        img1Tensor = torch.zeros((3, self.crop_size, self.crop_size), dtype=torch.float32)\n",
    "        img2Tensor = torch.zeros((3, self.crop_size, self.crop_size), dtype=torch.float32)\n",
    "        cmTensor = torch.zeros((1, self.crop_size, self.crop_size), dtype=torch.float32)\n",
    "        \n",
    "        crop1, crop2, cropcm = self.random_crop(img1[:,:,:], img2[:,:,:], cm[:,:,:], self.crop_size)\n",
    "        crop1, crop2, cropcm = self.random_flip(crop1[:,:,:], crop2[:,:,:], cropcm[:,:,:])\n",
    "        img1Tensor[:,:,:] = crop1.float()/255\n",
    "        img2Tensor[:,:,:] = crop2.float()/255\n",
    "        cmTensor[:,:,:] = cropcm.float()/255\n",
    "        #apply the same transformation to all images as batch dimension\n",
    "        return img1Tensor, img2Tensor, cmTensor\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple DataLoader class for our change detection dataset\n",
    "batch_size = 16\n",
    "\n",
    "weights = class_weights(\"data.csv\")\n",
    "weights = torch.tensor(weights[1]/weights[0]).to(device)\n",
    "\n",
    "train_dataset= ChangeDetectionDataset(data_dir=\"data\",csv_file=\"train.csv\", batch_size=batch_size, transform=None)\n",
    "val_dataset = ChangeDetectionDataset(data_dir=\"data\",csv_file=\"val.csv\", batch_size=1, transform=None)\n",
    "train_loader = DataLoader(batch_size=batch_size, dataset=train_dataset, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, shuffle=True)\n",
    "#Simple function to display a batch of images\n",
    "\n",
    "def show_batch(batch):\n",
    "    img1s, img2s, cms = batch\n",
    "\n",
    "    for i in range(len(img1s)):\n",
    "        img1 = img1s[i,:,:,:]\n",
    "        img2 = img2s[i,:,:,:]\n",
    "        cm = cms[i,:,:,:]\n",
    "        fig, ax = plt.subplots(1,3)\n",
    "        ax[0].imshow(img1.permute(1,2,0))\n",
    "        ax[1].imshow(img2.permute(1,2,0))\n",
    "        ax[2].imshow(cm.permute(1,2,0), cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "#a = next(iter(train_loader))\n",
    "#show_batch(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 10\n",
    "learning_rate = 0.0005\n",
    "model = Modele()\n",
    "loss_fn = nn.BCEWithLogitsLoss(pos_weight=weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_loss, val_loss = [], []\n",
    "train_precision, val_precision = [], []\n",
    "model = model.to(device)\n",
    "best_loss =1000\n",
    "\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "    model.train()\n",
    "    loss_cumu = 0\n",
    "    prec = 0\n",
    "    for img1,img2,cm in tqdm(train_loader, ascii=\" >=\"):\n",
    "        img1,img2,cm = img1.to(device),img2.to(device),cm.to(device)\n",
    "        #Forward pass\n",
    "        y_pred = model(img1, img2)\n",
    "        loss = loss_fn(y_pred, cm)\n",
    "        loss_cumu += loss\n",
    "        #Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        prec += torch.sum((torch.round(torch.sigmoid(y_pred))*cm))/(torch.sum(cm)+1)\n",
    "    train_loss.append(loss_cumu/len(train_loader))\n",
    "    train_precision.append(prec/len(train_loader))\n",
    "\n",
    "    model.eval()\n",
    "    loss_cumu=0\n",
    "    prec=0\n",
    "    with torch.no_grad():\n",
    "        for img1,img2,cm in val_loader:\n",
    "            img1,img2,cm = img1.to(device),img2.to(device),cm.to(device)\n",
    "            y_pred=model(img1,img2)\n",
    "            #y_pred, cm = torch.flatten(y_pred, start_dim=1), torch.flatten(cm, start_dim=1)\n",
    "            loss = loss_fn(y_pred,cm)\n",
    "            loss_cumu += loss\n",
    "            prec += torch.sum((torch.round(torch.sigmoid(y_pred))*cm))/(torch.sum(cm)+1)\n",
    "            if(loss_cumu/len(val_loader) < best_loss):\n",
    "                best_loss = loss_cumu/len(val_loader)\n",
    "                torch.save(model.state_dict(), \"best_model.pt\")\n",
    "        val_loss.append(loss_cumu/len(val_loader))\n",
    "        val_precision.append(prec/len(val_loader))\n",
    "    print(f\"Epoch {epoch+1} : Training, loss: {train_loss[-1]}, accuracy: {train_precision[-1]} | Validation, loss: {val_loss[-1]}, accuracy: {val_precision[-1]}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()\n",
    "model.eval()\n",
    "im1,im2,cm = next(iter(train_loader))\n",
    "cm_pred = torch.sigmoid(model(im1,im2, with_attn=False))\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(cm[0].permute(1,2,0), cmap='gray')\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(cm_pred.detach()[0].permute(1,2,0), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(im1[0].permute(1,2,0))\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(im2[0].permute(1,2,0))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "U-Net peut être utile\n",
    "\n",
    "# Soutenance\n",
    " - Explication du problème et comment le transcrire\n",
    " - Pré-traitement des données\n",
    " - Architecture du réseau\n",
    " - Présentation des résultats\n",
    " \n",
    "# Rendu \n",
    " - Slides de présentation (10 minutes+ 10 min de questions)\n",
    " - Notebook avec le code\n",
    "\n",
    "À rendre en séance. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
